{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import pickle\n",
    "import joblib\n",
    "\n",
    "#load the dataset\n",
    "dataset= joblib.load('datasetnew.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>49.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "34             0.0       12.0             0.0              48.0   \n",
       "399            5.0        4.0             0.0               1.0   \n",
       "834            0.0        8.0             0.0               8.0   \n",
       "1099           0.0        8.0             2.0              12.0   \n",
       "1115           6.0        8.0             0.0              19.0   \n",
       "1289          49.0        8.0           215.0            1000.0   \n",
       "1363           7.0        2.0             1.0               0.0   \n",
       "1391           0.0        4.0             0.0             168.0   \n",
       "1436          13.0        8.0             0.0             100.0   \n",
       "1644           0.0        8.0             0.0              28.0   \n",
       "\n",
       "      forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "34                84.0             120.0            7.0           45.0   \n",
       "399                3.0               6.0            0.0            4.0   \n",
       "834                8.0              12.0            1.0            2.0   \n",
       "1099              17.0              27.0            8.0           17.0   \n",
       "1115              19.0              30.0            4.0           15.0   \n",
       "1289            1800.0            2400.0          481.0          884.0   \n",
       "1363               0.0               0.0            2.0           17.0   \n",
       "1391             168.0             168.0           10.0           36.0   \n",
       "1436             100.0             100.0            5.0           25.0   \n",
       "1644              56.0              70.0            7.0           17.0   \n",
       "\n",
       "      sales_6_month  sales_9_month  ...  pieces_past_due  perf_6_month_avg  \\\n",
       "34             81.0          130.0  ...              0.0              0.98   \n",
       "399             7.0            9.0  ...              0.0              0.89   \n",
       "834             6.0            6.0  ...              0.0              0.78   \n",
       "1099           28.0           38.0  ...              0.0              0.42   \n",
       "1115           32.0           61.0  ...             18.0              0.18   \n",
       "1289         1358.0         2116.0  ...            200.0              0.00   \n",
       "1363           23.0           23.0  ...              0.0              0.99   \n",
       "1391           55.0           81.0  ...              0.0              0.84   \n",
       "1436           47.0           65.0  ...              0.0              0.97   \n",
       "1644           26.0           39.0  ...              0.0              0.98   \n",
       "\n",
       "      perf_12_month_avg  local_bo_qty  deck_risk  oe_constraint  ppap_risk  \\\n",
       "34                 0.89           0.0          0              0          0   \n",
       "399                0.90           0.0          0              0          0   \n",
       "834                0.78           0.0          0              0          0   \n",
       "1099               0.36           0.0          0              0          0   \n",
       "1115               0.31           0.0          0              0          0   \n",
       "1289               0.00           6.0          0              0          1   \n",
       "1363               0.90           0.0          1              0          0   \n",
       "1391               0.86           0.0          0              0          0   \n",
       "1436               0.96           0.0          0              0          0   \n",
       "1644               0.97           0.0          0              0          0   \n",
       "\n",
       "      stop_auto_buy  rev_stop  went_on_backorder  \n",
       "34                1         0                  1  \n",
       "399               1         0                  1  \n",
       "834               1         0                  1  \n",
       "1099              1         0                  1  \n",
       "1115              1         0                  1  \n",
       "1289              1         0                  1  \n",
       "1363              1         0                  1  \n",
       "1391              1         0                  1  \n",
       "1436              1         0                  1  \n",
       "1644              1         0                  1  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>national_inv</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>245.081555</td>\n",
       "      <td>9465.405980</td>\n",
       "      <td>-2999.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1370327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>7.178252</td>\n",
       "      <td>5.811139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_transit_qty</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>26.680643</td>\n",
       "      <td>715.753351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_3_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>163.835562</td>\n",
       "      <td>2448.302626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>252790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_6_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>289.543390</td>\n",
       "      <td>4622.241465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>495890.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast_9_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>406.808288</td>\n",
       "      <td>6602.215436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>719270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_1_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>39.904587</td>\n",
       "      <td>607.188377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>71757.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_3_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>119.580625</td>\n",
       "      <td>1855.757475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>226570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_6_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>224.919729</td>\n",
       "      <td>3661.144705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>450657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales_9_month</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>339.190295</td>\n",
       "      <td>5641.342220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>701532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_bank</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>37.642345</td>\n",
       "      <td>532.561667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>64551.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potential_issue</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.050174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces_past_due</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>2.650270</td>\n",
       "      <td>48.228089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>-4.911019</td>\n",
       "      <td>23.063788</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>-4.543861</td>\n",
       "      <td>22.337170</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_bo_qty</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>2.687815</td>\n",
       "      <td>50.245499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck_risk</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>0.397219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oe_constraint</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppap_risk</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.139954</td>\n",
       "      <td>0.346947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.961082</td>\n",
       "      <td>0.193404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_stop</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went_on_backorder</th>\n",
       "      <td>22586.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean          std     min   25%    50%  \\\n",
       "national_inv       22586.0  245.081555  9465.405980 -2999.0  1.00   5.00   \n",
       "lead_time          22586.0    7.178252     5.811139     0.0  2.00   8.00   \n",
       "in_transit_qty     22586.0   26.680643   715.753351     0.0  0.00   0.00   \n",
       "forecast_3_month   22586.0  163.835562  2448.302626     0.0  0.00   3.00   \n",
       "forecast_6_month   22586.0  289.543390  4622.241465     0.0  0.00   6.00   \n",
       "forecast_9_month   22586.0  406.808288  6602.215436     0.0  0.00   9.00   \n",
       "sales_1_month      22586.0   39.904587   607.188377     0.0  0.00   1.00   \n",
       "sales_3_month      22586.0  119.580625  1855.757475     0.0  0.00   4.00   \n",
       "sales_6_month      22586.0  224.919729  3661.144705     0.0  0.00   8.00   \n",
       "sales_9_month      22586.0  339.190295  5641.342220     0.0  1.00  11.00   \n",
       "min_bank           22586.0   37.642345   532.561667     0.0  0.00   0.00   \n",
       "potential_issue    22586.0    0.002524     0.050174     0.0  0.00   0.00   \n",
       "pieces_past_due    22586.0    2.650270    48.228089     0.0  0.00   0.00   \n",
       "perf_6_month_avg   22586.0   -4.911019    23.063788   -99.0  0.57   0.80   \n",
       "perf_12_month_avg  22586.0   -4.543861    22.337170   -99.0  0.58   0.78   \n",
       "local_bo_qty       22586.0    2.687815    50.245499     0.0  0.00   0.00   \n",
       "deck_risk          22586.0    0.196316     0.397219     0.0  0.00   0.00   \n",
       "oe_constraint      22586.0    0.000443     0.021037     0.0  0.00   0.00   \n",
       "ppap_risk          22586.0    0.139954     0.346947     0.0  0.00   0.00   \n",
       "stop_auto_buy      22586.0    0.961082     0.193404     0.0  1.00   1.00   \n",
       "rev_stop           22586.0    0.000177     0.013307     0.0  0.00   0.00   \n",
       "went_on_backorder  22586.0    0.500000     0.500011     0.0  0.00   0.50   \n",
       "\n",
       "                     75%        max  \n",
       "national_inv       24.00  1370327.0  \n",
       "lead_time           8.00       52.0  \n",
       "in_transit_qty      0.00    81720.0  \n",
       "forecast_3_month   24.00   252790.0  \n",
       "forecast_6_month   41.00   495890.0  \n",
       "forecast_9_month   60.00   719270.0  \n",
       "sales_1_month       7.00    71757.0  \n",
       "sales_3_month      21.00   226570.0  \n",
       "sales_6_month      39.00   450657.0  \n",
       "sales_9_month      57.00   701532.0  \n",
       "min_bank            4.00    64551.0  \n",
       "potential_issue     0.00        1.0  \n",
       "pieces_past_due     0.00     4200.0  \n",
       "perf_6_month_avg    0.95        1.0  \n",
       "perf_12_month_avg   0.94        1.0  \n",
       "local_bo_qty        0.00     2999.0  \n",
       "deck_risk           0.00        1.0  \n",
       "oe_constraint       0.00        1.0  \n",
       "ppap_risk           0.00        1.0  \n",
       "stop_auto_buy       1.00        1.0  \n",
       "rev_stop            0.00        1.0  \n",
       "went_on_backorder   1.00        1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploratory data analysis to find requirement of normalization/standarization\n",
    "\n",
    "dataset.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22586, 21)\n",
      "(22586,)\n",
      "Training shapes (X, y):  (15810, 21) (15810,)\n",
      "Testing shapes (X, y):  (6776, 21) (6776,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(dataset.iloc[:,0:21])\n",
    "y = np.array(dataset.went_on_backorder)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#70% data on training and 20% data on tesing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(\"Training shapes (X, y): \", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline-1 \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EllipticEnvelope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-903844ee004a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ----------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Anomaly detection method: EllipticEnvelope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menvelope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEllipticEnvelope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_fraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontamination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create an boolean indexing array to pick up outliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EllipticEnvelope' is not defined"
     ]
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "# Anomaly detection method: EllipticEnvelope\n",
    "envelope = EllipticEnvelope(support_fraction=1, contamination=0.2).fit(X_train)\n",
    "\n",
    "# Create an boolean indexing array to pick up outliers\n",
    "outliers = envelope.predict(X_train)==-1\n",
    "\n",
    "# Re-slice X train,y train into a cleaned dataset with outliers excluded\n",
    "X_ee_train = X_train[~outliers]\n",
    "y_ee_train = y_train[~outliers]\n",
    "print(X_ee_train.shape)\n",
    "print(y_ee_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
       "                                       ('PCA', PCA()), ('SVC', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'PCA__n_components': [20],\n",
       "                         'SVC__C': array([ 1000.,  4000.,  7000., 10000.]),\n",
       "                         'SVC__gamma': array([0.1       , 0.23333333, 0.36666667, 0.5       ]),\n",
       "                         'SVC__kernel': ['rbf']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "\n",
    "# Feature selection: PCA  Classifier: svc/ kernel SVC\n",
    "#model with outliers on test set\n",
    "#model1\n",
    "#defining pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('PCA', PCA()), \n",
    "    ('SVC', SVC())  \n",
    "])\n",
    "\n",
    "#hyperparameter tuning for pca and svc\n",
    "param_grid = {'PCA__n_components': [20],\n",
    "              'SVC__C': np.linspace(1000, 10000, num=4), \n",
    "              'SVC__gamma': np.linspace(0.1, 0.5, num=4), \n",
    "              'SVC__kernel': ['rbf']}\n",
    "\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model1 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model1.fit(X_ee_train, y_ee_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "11      27.401864      0.922744         0.753493        0.007899   \n",
      "6       16.279418      0.476982         0.790026        0.012372   \n",
      "15      36.402536      1.081011         0.795253        0.066289   \n",
      "14      31.260587      1.416480         0.761762        0.009342   \n",
      "13      23.661367      0.891306         0.866684        0.098478   \n",
      "7       18.559729      0.523359         0.776303        0.026145   \n",
      "10      22.148836      0.767508         0.768409        0.009063   \n",
      "9       18.591622      0.618538         0.834388        0.060129   \n",
      "5       13.461620      0.548058         0.853715        0.044101   \n",
      "8       13.344809      0.510437         0.861897        0.008616   \n",
      "2        8.446556      0.147409         0.832017        0.011122   \n",
      "3        8.796750      0.171998         0.808840        0.011039   \n",
      "12      15.948847      0.816654         0.866792        0.028473   \n",
      "4       10.266752      0.400289         0.905704        0.045645   \n",
      "1        7.925726      0.304848         0.864861        0.013533   \n",
      "0        7.122973      0.480463         0.918068        0.010978   \n",
      "\n",
      "   param_PCA__n_components param_SVC__C param_SVC__gamma param_SVC__kernel  \\\n",
      "11                      20       7000.0              0.5               rbf   \n",
      "6                       20       4000.0         0.366667               rbf   \n",
      "15                      20      10000.0              0.5               rbf   \n",
      "14                      20      10000.0         0.366667               rbf   \n",
      "13                      20      10000.0         0.233333               rbf   \n",
      "7                       20       4000.0              0.5               rbf   \n",
      "10                      20       7000.0         0.366667               rbf   \n",
      "9                       20       7000.0         0.233333               rbf   \n",
      "5                       20       4000.0         0.233333               rbf   \n",
      "8                       20       7000.0              0.1               rbf   \n",
      "2                       20       1000.0         0.366667               rbf   \n",
      "3                       20       1000.0              0.5               rbf   \n",
      "12                      20      10000.0              0.1               rbf   \n",
      "4                       20       4000.0              0.1               rbf   \n",
      "1                       20       1000.0         0.233333               rbf   \n",
      "0                       20       1000.0              0.1               rbf   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "11  {'PCA__n_components': 20, 'SVC__C': 7000.0, 'S...           0.843478   \n",
      "6   {'PCA__n_components': 20, 'SVC__C': 4000.0, 'S...           0.841107   \n",
      "15  {'PCA__n_components': 20, 'SVC__C': 10000.0, '...           0.839130   \n",
      "14  {'PCA__n_components': 20, 'SVC__C': 10000.0, '...           0.843478   \n",
      "13  {'PCA__n_components': 20, 'SVC__C': 10000.0, '...           0.839526   \n",
      "7   {'PCA__n_components': 20, 'SVC__C': 4000.0, 'S...           0.844664   \n",
      "10  {'PCA__n_components': 20, 'SVC__C': 7000.0, 'S...           0.840711   \n",
      "9   {'PCA__n_components': 20, 'SVC__C': 7000.0, 'S...           0.836759   \n",
      "5   {'PCA__n_components': 20, 'SVC__C': 4000.0, 'S...           0.834387   \n",
      "8   {'PCA__n_components': 20, 'SVC__C': 7000.0, 'S...           0.833992   \n",
      "2   {'PCA__n_components': 20, 'SVC__C': 1000.0, 'S...           0.836364   \n",
      "3   {'PCA__n_components': 20, 'SVC__C': 1000.0, 'S...           0.839130   \n",
      "12  {'PCA__n_components': 20, 'SVC__C': 10000.0, '...           0.833202   \n",
      "4   {'PCA__n_components': 20, 'SVC__C': 4000.0, 'S...           0.833597   \n",
      "1   {'PCA__n_components': 20, 'SVC__C': 1000.0, 'S...           0.834387   \n",
      "0   {'PCA__n_components': 20, 'SVC__C': 1000.0, 'S...           0.828854   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "11           0.854545           0.866798           0.856860   \n",
      "6            0.858498           0.862846           0.855674   \n",
      "15           0.855336           0.866403           0.856860   \n",
      "14           0.852964           0.865613           0.857256   \n",
      "13           0.860474           0.864822           0.852906   \n",
      "7            0.851383           0.865217           0.856070   \n",
      "10           0.854150           0.863636           0.856465   \n",
      "9            0.860079           0.861265           0.851720   \n",
      "5            0.858498           0.859289           0.852511   \n",
      "8            0.860079           0.859289           0.852906   \n",
      "2            0.856522           0.858893           0.848952   \n",
      "3            0.854545           0.855731           0.853697   \n",
      "12           0.860079           0.858103           0.852511   \n",
      "4            0.860870           0.854150           0.851720   \n",
      "1            0.857312           0.857708           0.850929   \n",
      "0            0.853755           0.856522           0.846184   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "11           0.862396         0.856816        0.007923                1  \n",
      "6            0.863978         0.856421        0.008219                2  \n",
      "15           0.862792         0.856104        0.009381                3  \n",
      "14           0.861210         0.856104        0.007577                4  \n",
      "13           0.862792         0.856104        0.009218                5  \n",
      "7            0.860815         0.855630        0.007173                6  \n",
      "10           0.862001         0.855393        0.008122                7  \n",
      "9            0.863187         0.854602        0.009744                8  \n",
      "5            0.862792         0.853495        0.010110                9  \n",
      "8            0.858837         0.853021        0.009849               10  \n",
      "2            0.862792         0.852704        0.009335               11  \n",
      "3            0.860024         0.852626        0.007090               12  \n",
      "12           0.858047         0.852388        0.009919               13  \n",
      "4            0.857256         0.851518        0.009471               14  \n",
      "1            0.857256         0.851518        0.008929               15  \n",
      "0            0.850534         0.847170        0.009784               16  \n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "model_results2 = pd.DataFrame.from_dict(model1.cv_results_)\n",
    "print(model_results2.sort_values(\"rank_test_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', MinMaxScaler()), ('PCA', PCA(n_components=20)),\n",
      "                ('SVC', SVC(C=7000.0, gamma=0.5))])\n",
      "Score of the best model: 0.8568157515117132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      3402\n",
      "           1       0.84      0.79      0.81      3374\n",
      "\n",
      "    accuracy                           0.82      6776\n",
      "   macro avg       0.82      0.82      0.82      6776\n",
      "weighted avg       0.82      0.82      0.82      6776\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2912</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722</td>\n",
       "      <td>2652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2912   490\n",
       "1   722  2652"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "#model with outliers on test set\n",
    "#model building and fitting model on train set\n",
    "print(\"Parameters of the best model are:\",model1.best_estimator_)\n",
    "print(\"Score of the best model:\", model1.best_score_)\n",
    "bestmodel1 = model1.best_estimator_\n",
    "predicted_y = model1.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      2675\n",
      "           1       0.85      0.88      0.87      2745\n",
      "\n",
      "    accuracy                           0.86      5420\n",
      "   macro avg       0.86      0.86      0.86      5420\n",
      "weighted avg       0.86      0.86      0.86      5420\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2266</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2266   409\n",
       "1   338  2407"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model after ourlier reduction on test data set\n",
    "\n",
    "#Anomaly detection and reduction on test set\n",
    "# Anomaly detection method: EllipticEnvelope\n",
    "envelope = EllipticEnvelope(support_fraction=1, contamination=0.2).fit(X_test)\n",
    "\n",
    "# Create an boolean indexing array to pick up outliers\n",
    "outliers = envelope.predict(X_test)==-1\n",
    "\n",
    "# Re-slice X train,y train into a cleaned dataset with outliers excluded\n",
    "X_ee_test = X_test[~outliers]\n",
    "y_ee_test = y_test[~outliers]\n",
    "\n",
    "\n",
    "#model building and fitting model on train set\n",
    "\n",
    "predicted_y = model1.predict(X_ee_test)\n",
    "print(classification_report(y_ee_test, predicted_y))\n",
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_ee_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scale', MinMaxScaler()),\n",
       "                                       ('PCA', PCA()), ('SVC', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'PCA__n_components': [10, 20],\n",
       "                         'SVC__C': [500, 1000, 5000, 10000],\n",
       "                         'SVC__gamma': [0.1, 0.5], 'SVC__kernel': ['rbf']})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "#another way of model1\n",
    "\n",
    "# Feature Selection: PCA , Classifier: SVC/ Kernel SVC\n",
    "# Pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('PCA', PCA()), \n",
    "    ('SVC', SVC())  \n",
    "])\n",
    "\n",
    "# hyperparameter tuning of classifiers and feature selection method\n",
    "\n",
    "param_grid = {'SVC__C': [500, 1000, 5000, 10000], \n",
    "              'SVC__gamma': [0.1, 0.5], \n",
    "              'PCA__n_components': [10, 20],\n",
    "              'SVC__kernel': ['rbf']}\n",
    "\n",
    "\n",
    "model1n = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model1n.fit(X_ee_train, y_ee_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "13      21.405757      0.903835         0.766710        0.016909   \n",
      "15      35.882653      1.397312         0.742288        0.018743   \n",
      "11       8.535677      0.144737         0.814909        0.019983   \n",
      "14      15.564561      0.802227         0.858056        0.009200   \n",
      "12      11.298419      0.303327         0.882565        0.013260   \n",
      "9        7.027674      0.128893         0.858346        0.024250   \n",
      "7       32.556818      1.312969         0.671891        0.011544   \n",
      "10       7.000104      0.493210         0.923907        0.011336   \n",
      "8        6.468229      0.468659         1.003018        0.096377   \n",
      "5       19.040603      0.922520         0.696299        0.010870   \n",
      "3        8.708659      0.300155         0.734626        0.040387   \n",
      "1        7.220804      0.215060         0.762125        0.020741   \n",
      "6       14.684410      0.516697         0.786570        0.017308   \n",
      "4       10.723770      0.355259         0.785646        0.034383   \n",
      "2        7.122081      0.485781         0.844149        0.080071   \n",
      "0        6.598025      0.254450         0.822050        0.022222   \n",
      "\n",
      "   param_PCA__n_components param_SVC__C param_SVC__gamma param_SVC__kernel  \\\n",
      "13                      20         5000              0.5               rbf   \n",
      "15                      20        10000              0.5               rbf   \n",
      "11                      20         1000              0.5               rbf   \n",
      "14                      20        10000              0.1               rbf   \n",
      "12                      20         5000              0.1               rbf   \n",
      "9                       20          500              0.5               rbf   \n",
      "7                       10        10000              0.5               rbf   \n",
      "10                      20         1000              0.1               rbf   \n",
      "8                       20          500              0.1               rbf   \n",
      "5                       10         5000              0.5               rbf   \n",
      "3                       10         1000              0.5               rbf   \n",
      "1                       10          500              0.5               rbf   \n",
      "6                       10        10000              0.1               rbf   \n",
      "4                       10         5000              0.1               rbf   \n",
      "2                       10         1000              0.1               rbf   \n",
      "0                       10          500              0.1               rbf   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "13  {'PCA__n_components': 20, 'SVC__C': 5000, 'SVC...           0.846640   \n",
      "15  {'PCA__n_components': 20, 'SVC__C': 10000, 'SV...           0.839130   \n",
      "11  {'PCA__n_components': 20, 'SVC__C': 1000, 'SVC...           0.839130   \n",
      "14  {'PCA__n_components': 20, 'SVC__C': 10000, 'SV...           0.833202   \n",
      "12  {'PCA__n_components': 20, 'SVC__C': 5000, 'SVC...           0.834387   \n",
      "9   {'PCA__n_components': 20, 'SVC__C': 500, 'SVC_...           0.834783   \n",
      "7   {'PCA__n_components': 10, 'SVC__C': 10000, 'SV...           0.830830   \n",
      "10  {'PCA__n_components': 20, 'SVC__C': 1000, 'SVC...           0.828854   \n",
      "8   {'PCA__n_components': 20, 'SVC__C': 500, 'SVC_...           0.827668   \n",
      "5   {'PCA__n_components': 10, 'SVC__C': 5000, 'SVC...           0.826087   \n",
      "3   {'PCA__n_components': 10, 'SVC__C': 1000, 'SVC...           0.823320   \n",
      "1   {'PCA__n_components': 10, 'SVC__C': 500, 'SVC_...           0.821739   \n",
      "6   {'PCA__n_components': 10, 'SVC__C': 10000, 'SV...           0.811858   \n",
      "4   {'PCA__n_components': 10, 'SVC__C': 5000, 'SVC...           0.814229   \n",
      "2   {'PCA__n_components': 10, 'SVC__C': 1000, 'SVC...           0.805138   \n",
      "0   {'PCA__n_components': 10, 'SVC__C': 500, 'SVC_...           0.803162   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "13           0.853755           0.865613           0.858047   \n",
      "15           0.855336           0.866403           0.856860   \n",
      "11           0.854545           0.855731           0.853697   \n",
      "14           0.860079           0.858103           0.852511   \n",
      "12           0.860474           0.855336           0.852906   \n",
      "9            0.856917           0.858893           0.849348   \n",
      "7            0.851779           0.851383           0.848952   \n",
      "10           0.853755           0.856522           0.846184   \n",
      "8            0.852569           0.852964           0.843812   \n",
      "5            0.849802           0.846245           0.847766   \n",
      "3            0.846640           0.839130           0.845789   \n",
      "1            0.846640           0.837154           0.839462   \n",
      "6            0.843478           0.836759           0.837485   \n",
      "4            0.841107           0.838340           0.835904   \n",
      "2            0.841107           0.827273           0.831949   \n",
      "0            0.837549           0.825692           0.830368   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "13           0.860815         0.856974        0.006445                1  \n",
      "15           0.862792         0.856104        0.009381                2  \n",
      "11           0.860024         0.852626        0.007090                3  \n",
      "14           0.858047         0.852388        0.009919                4  \n",
      "12           0.856860         0.851993        0.009139                5  \n",
      "9            0.860024         0.851993        0.009376                6  \n",
      "7            0.855279         0.847645        0.008646                7  \n",
      "10           0.850534         0.847170        0.009784                8  \n",
      "8            0.848952         0.845193        0.009359                9  \n",
      "5            0.852115         0.844403        0.009368               10  \n",
      "3            0.844998         0.839976        0.008736               11  \n",
      "1            0.842230         0.837445        0.008465               12  \n",
      "6            0.842626         0.834441        0.011604               13  \n",
      "4            0.837881         0.833492        0.009774               14  \n",
      "2            0.833136         0.827721        0.012137               15  \n",
      "0            0.833136         0.825981        0.012042               16  \n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "model_results2 = pd.DataFrame.from_dict(model1n.cv_results_)\n",
    "print(model_results2.sort_values(\"rank_test_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', MinMaxScaler()), ('PCA', PCA(n_components=20)),\n",
      "                ('SVC', SVC(C=5000, gamma=0.5))])\n",
      "Score of the best model: 0.8569738230205506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      3402\n",
      "           1       0.85      0.78      0.81      3374\n",
      "\n",
      "    accuracy                           0.82      6776\n",
      "   macro avg       0.82      0.82      0.82      6776\n",
      "weighted avg       0.82      0.82      0.82      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2920</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>728</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2920   482\n",
       "1   728  2646"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model1n.best_estimator_)\n",
    "print(\"Score of the best model:\", model1n.best_score_)\n",
    "predicted_y = model1n.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "\n",
    "> For the pipeline 1, I used Elliptic Envelope for Anomaly detection, PCA for feature selection and KernelSVC classification method for developing model 1.\n",
    "\n",
    "> For hyperparameter testing, I considered some KernelSVC parameters for example, C, gamma, and kernel.\n",
    "- After considering all kind of ranges I found that 20 features and 'rbf' kernel are providing better model accuracy.\n",
    "- For C and gamma value, at first I identified the range of values with better accuracy from the wide variety of ranges such as [0.001, 0.01, 0.1 0.5 1 5 10 20 50 100 500 1000 5000 10000] and then used np.linespace and generated few random numbers for that range.\n",
    "- Lastly, I computed the mean of cross validation accuracy which came out to be 85%.\n",
    "\n",
    "> Finally, as part of model evaluation, I ran the model on test data with and without outliers and got average f1-score as 81% and 86%. The model worked better on the test data without outliers.\n",
    "\n",
    "> Additionally, I checked here whether there is any differene in result if we assign manual value (instead of using a function) on hyperparameter testing. I found that there is no significant difference on the overall model accuracy and prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15019, 21)\n",
      "(15019,)\n"
     ]
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "#model2 with outliers on test set\n",
    "# Anomaly detection method: IsolationForest \n",
    "iso_forest = IsolationForest(contamination=0.05).fit(X_train, y_train)\n",
    "\n",
    "iso_outliers = iso_forest.predict(X_train)==-1\n",
    "\n",
    "X_iso_train = X_train[~iso_outliers]\n",
    "y_iso_train = y_train[~iso_outliers]\n",
    "\n",
    "print(X_iso_train.shape)\n",
    "print(y_iso_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.70091211        nan 0.69725146        nan 0.69845013\n",
      "        nan 0.69685082        nan 0.69878291        nan 0.73200605\n",
      "        nan 0.73779842        nan 0.74152703        nan 0.7514478\n",
      "        nan 0.73260401]\n",
      "  category=UserWarning\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('FA', FactorAnalysis()),\n",
       "                                       ('LinearSVC', LinearSVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'FA__n_components': [15, 20],\n",
       "                         'LinearSVC__C': [10, 20, 30, 40, 50],\n",
       "                         'LinearSVC__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "#model2\n",
    "#feature selection method: Factor Analysis and classifier: LinearSVC\n",
    "#pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('FA', FactorAnalysis()),\n",
    "    ('LinearSVC', LinearSVC())                 \n",
    "])\n",
    "\n",
    "# hyperparameter tunning of the classifier and feature selection method\n",
    "param_grid = {'FA__n_components': [15, 20],\n",
    "              'LinearSVC__C': [10, 20, 30, 40, 50],\n",
    "              'LinearSVC__penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "\n",
    "# building and fitting model on train set\n",
    "model2 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model2.fit(X_iso_train, y_iso_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "17       2.936180      0.147945         0.002229        0.000045   \n",
      "15       2.965025      0.126044         0.002250        0.000064   \n",
      "13       2.924571      0.101103         0.002329        0.000075   \n",
      "19       2.679536      0.193225         0.002202        0.000074   \n",
      "11       2.788662      0.107845         0.002305        0.000134   \n",
      "1        4.157096      0.775368         0.002215        0.000132   \n",
      "9        4.011814      0.754822         0.002172        0.000020   \n",
      "5        3.930265      0.656304         0.002195        0.000094   \n",
      "3        4.062073      0.673041         0.002234        0.000160   \n",
      "7        4.011479      0.683250         0.002192        0.000120   \n",
      "8        2.744943      0.670006         0.000000        0.000000   \n",
      "18       1.303190      0.115428         0.000000        0.000000   \n",
      "10       1.338654      0.113754         0.000000        0.000000   \n",
      "12       1.303090      0.079143         0.000000        0.000000   \n",
      "4        2.766956      0.673541         0.000000        0.000000   \n",
      "14       1.329076      0.139475         0.000000        0.000000   \n",
      "16       1.280581      0.106790         0.000000        0.000000   \n",
      "2        2.721676      0.688418         0.000000        0.000000   \n",
      "6        2.777221      0.688307         0.000000        0.000000   \n",
      "0        2.791210      0.734079         0.000000        0.000000   \n",
      "\n",
      "   param_FA__n_components param_LinearSVC__C param_LinearSVC__penalty  \\\n",
      "17                     20                 40                       l2   \n",
      "15                     20                 30                       l2   \n",
      "13                     20                 20                       l2   \n",
      "19                     20                 50                       l2   \n",
      "11                     20                 10                       l2   \n",
      "1                      15                 10                       l2   \n",
      "9                      15                 50                       l2   \n",
      "5                      15                 30                       l2   \n",
      "3                      15                 20                       l2   \n",
      "7                      15                 40                       l2   \n",
      "8                      15                 50                       l1   \n",
      "18                     20                 50                       l1   \n",
      "10                     20                 10                       l1   \n",
      "12                     20                 20                       l1   \n",
      "4                      15                 30                       l1   \n",
      "14                     20                 30                       l1   \n",
      "16                     20                 40                       l1   \n",
      "2                      15                 20                       l1   \n",
      "6                      15                 40                       l1   \n",
      "0                      15                 10                       l1   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "17  {'FA__n_components': 20, 'LinearSVC__C': 40, '...           0.776631   \n",
      "15  {'FA__n_components': 20, 'LinearSVC__C': 30, '...           0.765979   \n",
      "13  {'FA__n_components': 20, 'LinearSVC__C': 20, '...           0.759321   \n",
      "19  {'FA__n_components': 20, 'LinearSVC__C': 50, '...           0.763981   \n",
      "11  {'FA__n_components': 20, 'LinearSVC__C': 10, '...           0.754993   \n",
      "1   {'FA__n_components': 15, 'LinearSVC__C': 10, '...           0.709387   \n",
      "9   {'FA__n_components': 15, 'LinearSVC__C': 50, '...           0.698735   \n",
      "5   {'FA__n_components': 15, 'LinearSVC__C': 30, '...           0.667111   \n",
      "3   {'FA__n_components': 15, 'LinearSVC__C': 20, '...           0.688748   \n",
      "7   {'FA__n_components': 15, 'LinearSVC__C': 40, '...           0.728362   \n",
      "8   {'FA__n_components': 15, 'LinearSVC__C': 50, '...                NaN   \n",
      "18  {'FA__n_components': 20, 'LinearSVC__C': 50, '...                NaN   \n",
      "10  {'FA__n_components': 20, 'LinearSVC__C': 10, '...                NaN   \n",
      "12  {'FA__n_components': 20, 'LinearSVC__C': 20, '...                NaN   \n",
      "4   {'FA__n_components': 15, 'LinearSVC__C': 30, '...                NaN   \n",
      "14  {'FA__n_components': 20, 'LinearSVC__C': 30, '...                NaN   \n",
      "16  {'FA__n_components': 20, 'LinearSVC__C': 40, '...                NaN   \n",
      "2   {'FA__n_components': 15, 'LinearSVC__C': 20, '...                NaN   \n",
      "6   {'FA__n_components': 15, 'LinearSVC__C': 40, '...                NaN   \n",
      "0   {'FA__n_components': 15, 'LinearSVC__C': 10, '...                NaN   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "17           0.786618           0.729028           0.719041   \n",
      "15           0.770972           0.735020           0.699734   \n",
      "13           0.772636           0.719707           0.705060   \n",
      "19           0.790280           0.689414           0.707057   \n",
      "11           0.764980           0.718043           0.691079   \n",
      "1            0.679760           0.712383           0.703063   \n",
      "9            0.667443           0.705726           0.702730   \n",
      "5            0.667776           0.721704           0.714714   \n",
      "3            0.698402           0.712716           0.669441   \n",
      "7            0.692077           0.653129           0.711385   \n",
      "8                 NaN                NaN                NaN   \n",
      "18                NaN                NaN                NaN   \n",
      "10                NaN                NaN                NaN   \n",
      "12                NaN                NaN                NaN   \n",
      "4                 NaN                NaN                NaN   \n",
      "14                NaN                NaN                NaN   \n",
      "16                NaN                NaN                NaN   \n",
      "2                 NaN                NaN                NaN   \n",
      "6                 NaN                NaN                NaN   \n",
      "0                 NaN                NaN                NaN   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "17           0.745921         0.751448        0.026285                1  \n",
      "15           0.735931         0.741527        0.025633                2  \n",
      "13           0.732268         0.737798        0.024926                3  \n",
      "19           0.712288         0.732604        0.038057                4  \n",
      "11           0.730936         0.732006        0.026408                5  \n",
      "1            0.699967         0.700912        0.011457                6  \n",
      "9            0.719281         0.698783        0.017124                7  \n",
      "5            0.720946         0.698450        0.025434                8  \n",
      "3            0.716950         0.697251        0.017171                9  \n",
      "7            0.699301         0.696851        0.025078               10  \n",
      "8                 NaN              NaN             NaN               11  \n",
      "18                NaN              NaN             NaN               12  \n",
      "10                NaN              NaN             NaN               13  \n",
      "12                NaN              NaN             NaN               14  \n",
      "4                 NaN              NaN             NaN               15  \n",
      "14                NaN              NaN             NaN               16  \n",
      "16                NaN              NaN             NaN               17  \n",
      "2                 NaN              NaN             NaN               18  \n",
      "6                 NaN              NaN             NaN               19  \n",
      "0                 NaN              NaN             NaN               20  \n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "model_results2 = pd.DataFrame.from_dict(model2.cv_results_)\n",
    "print(model_results2.sort_values(\"rank_test_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('FA', FactorAnalysis(n_components=20)),\n",
      "                ('LinearSVC', LinearSVC(C=40))])\n",
      "Score of the best model: 0.7514477976528575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70      3402\n",
      "           1       0.68      0.88      0.77      3374\n",
      "\n",
      "    accuracy                           0.74      6776\n",
      "   macro avg       0.76      0.74      0.73      6776\n",
      "weighted avg       0.76      0.74      0.73      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2034</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412</td>\n",
       "      <td>2962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2034  1368\n",
       "1   412  2962"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model2.best_estimator_)\n",
    "print(\"Score of the best model:\", model2.best_score_)\n",
    "bestmodel2 = model2.best_estimator_\n",
    "predicted_y = model2.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70      3224\n",
      "           1       0.69      0.88      0.77      3213\n",
      "\n",
      "    accuracy                           0.74      6437\n",
      "   macro avg       0.76      0.74      0.73      6437\n",
      "weighted avg       0.76      0.74      0.73      6437\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1929</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394</td>\n",
       "      <td>2819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1929  1295\n",
       "1   394  2819"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2 with only inliers on test set\n",
    "\n",
    "#model2 with outliers on test set\n",
    "# Anomaly detection method: IsolationForest \n",
    "iso_forest = IsolationForest(contamination=0.05).fit(X_test, y_test)\n",
    "\n",
    "iso_outliers = iso_forest.predict(X_test)==-1\n",
    "\n",
    "X_iso_test = X_test[~iso_outliers]\n",
    "y_iso_test = y_test[~iso_outliers]\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "predicted_y = model2.predict(X_iso_test)\n",
    "print(classification_report(y_iso_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_iso_test, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "> For the 2nd pipeline, I have used Isolation forest as Anomaly detection, Factor Analysis for feature selection followed by a Linear SVC classifier.\n",
    "\n",
    "> For random forest classifier I have considered important hyperparametrs, such as, C values and penalty.\n",
    "> For hyperparameter tuning, I tested with [0.001, 0.01, 0.1 0.5 1 5 10 20 50 100 500 1000 5000 10000] range.\n",
    "> I found that range of C value 10- 50 worked better than others and\n",
    "  and penalty 'l2' worked better than 'l1'.\n",
    "   \n",
    "- I got model accuracy of 74%.\n",
    "\n",
    "> For evaluating the model, I applied it to the test dataset with and without outliers and got an average f1-score of 75% in both the cases. \n",
    "\n",
    "> Here, I experimented with two standarization detection method (minmax scalar and standard scalar) but did not get any significant differences in results. So, I used standard scalar for the final result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "\n",
    "#Anomaly detection method:Local outlier factor\n",
    "lof_model = LocalOutlierFactor(n_neighbors=20)\n",
    "lof=lof_model.fit(X_train)\n",
    "train_outliers = lof_model.fit_predict(X_train)\n",
    "X_lof_train = X_train[train_outliers == 1]\n",
    "y_lof_train = y_train[train_outliers == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('RFE',\n",
       "                                        RFE(estimator=RandomForestClassifier())),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'RFE__n_features_to_select': [10, 15],\n",
       "                         'rf__criterion': ['gini', 'entropy'],\n",
       "                         'rf__min_samples_split': [2, 3, 4],\n",
       "                         'rf__n_estimators': [50, 100, 1000]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "#model 3\n",
    "#model with outlier ontrain set\n",
    "#feature selection method: factor analysis, Classifier: random forest\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=RandomForestClassifier())),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'RFE__n_features_to_select': [10, 15],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model3 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model3.fit(X_lof_train, y_lof_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "29      26.256861      0.516521         0.677904        0.020587   \n",
      "19      10.887834      0.045051         0.064631        0.001502   \n",
      "28      11.256159      0.036070         0.065990        0.000699   \n",
      "32      25.975243      0.214289         0.660366        0.008512   \n",
      "20      22.349998      0.126186         0.674122        0.015259   \n",
      "35      26.080022      0.201758         0.668486        0.063980   \n",
      "23      22.291959      0.173757         0.662475        0.006202   \n",
      "18      10.288435      0.035826         0.033979        0.001248   \n",
      "31      11.275072      0.022975         0.065635        0.000489   \n",
      "22      11.010592      0.071385         0.064152        0.001601   \n",
      "33      10.506011      0.058887         0.034847        0.003692   \n",
      "27      10.429851      0.042954         0.033868        0.002090   \n",
      "26      22.212767      0.104337         0.644953        0.005552   \n",
      "34      11.480753      0.124960         0.064747        0.001407   \n",
      "30      10.514610      0.058954         0.033477        0.000650   \n",
      "25      11.000239      0.069145         0.064851        0.001451   \n",
      "24      10.333314      0.079602         0.032576        0.000604   \n",
      "21      10.286835      0.006576         0.033767        0.001902   \n",
      "2       30.815393      0.129568         0.658090        0.004378   \n",
      "1       18.029174      0.074523         0.063031        0.000629   \n",
      "11      35.580838      0.348618         0.653618        0.015392   \n",
      "14      35.322717      0.173740         0.627665        0.005634   \n",
      "5       30.770081      0.205978         0.642979        0.024657   \n",
      "10      18.525549      0.137170         0.064625        0.001548   \n",
      "3       17.414389      0.186570         0.032605        0.001109   \n",
      "16      18.725902      0.180535         0.063391        0.002172   \n",
      "13      18.537248      0.321538         0.064939        0.001552   \n",
      "0       17.372391      0.092050         0.032593        0.000808   \n",
      "7       18.063994      0.102970         0.062785        0.001211   \n",
      "8       30.906914      0.608841         0.612577        0.006563   \n",
      "4       18.171943      0.216441         0.062659        0.001798   \n",
      "12      17.839723      0.327123         0.032932        0.001213   \n",
      "17      35.298311      0.285784         0.600974        0.014402   \n",
      "9       17.493196      0.059023         0.032693        0.000745   \n",
      "15      17.524291      0.157401         0.032537        0.001406   \n",
      "6       17.291913      0.052885         0.032101        0.000532   \n",
      "\n",
      "   param_RFE__n_features_to_select param_rf__criterion  \\\n",
      "29                              15             entropy   \n",
      "19                              15                gini   \n",
      "28                              15             entropy   \n",
      "32                              15             entropy   \n",
      "20                              15                gini   \n",
      "35                              15             entropy   \n",
      "23                              15                gini   \n",
      "18                              15                gini   \n",
      "31                              15             entropy   \n",
      "22                              15                gini   \n",
      "33                              15             entropy   \n",
      "27                              15             entropy   \n",
      "26                              15                gini   \n",
      "34                              15             entropy   \n",
      "30                              15             entropy   \n",
      "25                              15                gini   \n",
      "24                              15                gini   \n",
      "21                              15                gini   \n",
      "2                               10                gini   \n",
      "1                               10                gini   \n",
      "11                              10             entropy   \n",
      "14                              10             entropy   \n",
      "5                               10                gini   \n",
      "10                              10             entropy   \n",
      "3                               10                gini   \n",
      "16                              10             entropy   \n",
      "13                              10             entropy   \n",
      "0                               10                gini   \n",
      "7                               10                gini   \n",
      "8                               10                gini   \n",
      "4                               10                gini   \n",
      "12                              10             entropy   \n",
      "17                              10             entropy   \n",
      "9                               10             entropy   \n",
      "15                              10             entropy   \n",
      "6                               10                gini   \n",
      "\n",
      "   param_rf__min_samples_split param_rf__n_estimators  \\\n",
      "29                           2                   1000   \n",
      "19                           2                    100   \n",
      "28                           2                    100   \n",
      "32                           3                   1000   \n",
      "20                           2                   1000   \n",
      "35                           4                   1000   \n",
      "23                           3                   1000   \n",
      "18                           2                     50   \n",
      "31                           3                    100   \n",
      "22                           3                    100   \n",
      "33                           4                     50   \n",
      "27                           2                     50   \n",
      "26                           4                   1000   \n",
      "34                           4                    100   \n",
      "30                           3                     50   \n",
      "25                           4                    100   \n",
      "24                           4                     50   \n",
      "21                           3                     50   \n",
      "2                            2                   1000   \n",
      "1                            2                    100   \n",
      "11                           2                   1000   \n",
      "14                           3                   1000   \n",
      "5                            3                   1000   \n",
      "10                           2                    100   \n",
      "3                            3                     50   \n",
      "16                           4                    100   \n",
      "13                           3                    100   \n",
      "0                            2                     50   \n",
      "7                            4                    100   \n",
      "8                            4                   1000   \n",
      "4                            3                    100   \n",
      "12                           3                     50   \n",
      "17                           4                   1000   \n",
      "9                            2                     50   \n",
      "15                           4                     50   \n",
      "6                            4                     50   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "29  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.898515   \n",
      "19  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.899929   \n",
      "28  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.903465   \n",
      "32  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895686   \n",
      "20  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.898161   \n",
      "35  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895686   \n",
      "23  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.896040   \n",
      "18  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.897100   \n",
      "31  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.894979   \n",
      "22  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.898515   \n",
      "33  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895332   \n",
      "27  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895332   \n",
      "26  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.893564   \n",
      "34  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.892857   \n",
      "30  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.894625   \n",
      "25  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895332   \n",
      "24  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.895332   \n",
      "21  {'RFE__n_features_to_select': 15, 'rf__criteri...           0.894272   \n",
      "2   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.894979   \n",
      "1   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.895686   \n",
      "11  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.894979   \n",
      "14  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.894979   \n",
      "5   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.893564   \n",
      "10  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.894625   \n",
      "3   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.891796   \n",
      "16  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.893211   \n",
      "13  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.896393   \n",
      "0   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.889321   \n",
      "7   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.891089   \n",
      "8   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.893564   \n",
      "4   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.893564   \n",
      "12  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.894625   \n",
      "17  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.891796   \n",
      "9   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.891089   \n",
      "15  {'RFE__n_features_to_select': 10, 'rf__criteri...           0.893564   \n",
      "6   {'RFE__n_features_to_select': 10, 'rf__criteri...           0.891796   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "29           0.906294           0.917227           0.914043   \n",
      "19           0.907001           0.912982           0.911921   \n",
      "28           0.904880           0.909091           0.913336   \n",
      "32           0.906294           0.914751           0.914043   \n",
      "20           0.906294           0.912274           0.912628   \n",
      "35           0.905941           0.913336           0.911921   \n",
      "23           0.904526           0.915104           0.911567   \n",
      "18           0.906294           0.913336           0.911213   \n",
      "31           0.904880           0.911921           0.912274   \n",
      "22           0.903112           0.913689           0.909091   \n",
      "33           0.899929           0.915812           0.911921   \n",
      "27           0.904526           0.911921           0.909445   \n",
      "26           0.903465           0.912628           0.909091   \n",
      "34           0.903819           0.910860           0.909798   \n",
      "30           0.902758           0.908383           0.910152   \n",
      "25           0.904173           0.910506           0.907676   \n",
      "24           0.901344           0.908383           0.908737   \n",
      "21           0.901344           0.910506           0.909798   \n",
      "2            0.899576           0.905907           0.902370   \n",
      "1            0.898868           0.906969           0.898479   \n",
      "11           0.898161           0.903431           0.902370   \n",
      "14           0.898515           0.902370           0.901663   \n",
      "5            0.897808           0.904492           0.900248   \n",
      "10           0.899576           0.899186           0.899894   \n",
      "3            0.897100           0.904846           0.900955   \n",
      "16           0.898868           0.903431           0.900601   \n",
      "13           0.896747           0.900248           0.901309   \n",
      "0            0.899576           0.900601           0.900601   \n",
      "7            0.898161           0.904139           0.897771   \n",
      "8            0.896040           0.901663           0.902016   \n",
      "4            0.896393           0.900955           0.898479   \n",
      "12           0.895686           0.902016           0.898833   \n",
      "17           0.895686           0.900248           0.900601   \n",
      "9            0.898515           0.898833           0.899186   \n",
      "15           0.895332           0.897771           0.899540   \n",
      "6            0.887199           0.899186           0.896357   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "29           0.910860         0.909388        0.006528                1  \n",
      "19           0.910506         0.908468        0.004723                2  \n",
      "28           0.910860         0.908326        0.003677                3  \n",
      "32           0.909445         0.908044        0.006910                4  \n",
      "20           0.909798         0.907831        0.005338                5  \n",
      "35           0.909445         0.907266        0.006310                6  \n",
      "23           0.908383         0.907124        0.006552                7  \n",
      "18           0.905907         0.906770        0.005609                8  \n",
      "31           0.908383         0.906487        0.006350                9  \n",
      "22           0.906261         0.906134        0.005158               10  \n",
      "33           0.906615         0.905922        0.007514               11  \n",
      "27           0.907676         0.905780        0.005753               12  \n",
      "26           0.907322         0.905214        0.006530               13  \n",
      "34           0.907676         0.905002        0.006532               14  \n",
      "30           0.908030         0.904790        0.005650               15  \n",
      "25           0.906261         0.904790        0.005157               16  \n",
      "24           0.908030         0.904365        0.005280               17  \n",
      "21           0.904139         0.904012        0.005961               18  \n",
      "2            0.894942         0.899555        0.004254               19  \n",
      "1            0.894942         0.898989        0.004272               20  \n",
      "11           0.894234         0.898635        0.003739               21  \n",
      "14           0.893880         0.898281        0.003420               22  \n",
      "5            0.894234         0.898069        0.004027               23  \n",
      "10           0.896357         0.897928        0.002076               24  \n",
      "3            0.894588         0.897857        0.004614               25  \n",
      "16           0.892819         0.897786        0.004161               26  \n",
      "13           0.894234         0.897786        0.002612               27  \n",
      "0            0.898125         0.897645        0.004260               28  \n",
      "7            0.894588         0.897150        0.004325               29  \n",
      "8            0.892466         0.897150        0.004002               30  \n",
      "4            0.895649         0.897008        0.002523               31  \n",
      "12           0.892466         0.896725        0.003349               32  \n",
      "17           0.893527         0.896372        0.003533               33  \n",
      "9            0.893173         0.896159        0.003361               34  \n",
      "15           0.893880         0.896018        0.002304               35  \n",
      "6            0.893173         0.893542        0.004079               36  \n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "model_results2 = pd.DataFrame.from_dict(model3.cv_results_)\n",
    "print(model_results2.sort_values(\"rank_test_score\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=RandomForestClassifier(),\n",
      "                     n_features_to_select=15)),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(criterion='entropy',\n",
      "                                        n_estimators=1000))])\n",
      "Score of the best model: 0.9093877036397359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3402\n",
      "           1       0.89      0.93      0.91      3374\n",
      "\n",
      "    accuracy                           0.91      6776\n",
      "   macro avg       0.91      0.91      0.91      6776\n",
      "weighted avg       0.91      0.91      0.91      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3029</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>3141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3029   373\n",
       "1   233  3141"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model3.best_estimator_)\n",
    "print(\"Score of the best model:\", model3.best_score_)\n",
    "bestmodel3 = model3.best_estimator_\n",
    "predicted_y = model3.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      2968\n",
      "           1       0.90      0.94      0.92      3091\n",
      "\n",
      "    accuracy                           0.91      6059\n",
      "   macro avg       0.92      0.91      0.91      6059\n",
      "weighted avg       0.92      0.91      0.91      6059\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2643</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2643   325\n",
       "1   191  2900"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model without outliers on test data\n",
    "\n",
    "#Anomaly detection method:Local outlier factor\n",
    "lof_model = LocalOutlierFactor(n_neighbors=20)\n",
    "lof_model.fit(X_test)\n",
    "test_outliers = lof_model.fit_predict(X_test)\n",
    "X_lof_test = X_test[test_outliers == 1]\n",
    "y_lof_test = y_test[test_outliers == 1]\n",
    "\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "predicted_y = model3.predict(X_lof_test)\n",
    "print(classification_report(y_lof_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_lof_test, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# ---------------------------------------------\n",
    "\n",
    "> For the 3rd pipeline, I have used Local outlier detection method for Anomaly detection, RFE for feature selection followed by a Random Forest classifier.\n",
    "\n",
    "> For random forest classifier I have considered important hyperparametrs, such as, n_estimators, min_sample_split and criterion.\n",
    "- I tried different ranges of those parameters ([0.001, 0.01, 0.1 0.5 1 5 10 20 50 100 500 1000 5000 10000]) and found that:\n",
    "   n_estimators worked well on the [100 to 1000] range,\n",
    "   min sample split worked well on [2,3,4] and \n",
    "   criterion 'gini' and 'entropy' gave better results than the other one.\n",
    "- I got best model accuracy of 90%.\n",
    "\n",
    "> For evaluating the model, I applied it to the test dataset with and without outliers and got a average f1-score of 91% and 92%.\n",
    "\n",
    "> Here, I experimented with many feature selection method and classifier methods outlined following and this the best model. I saved it for part 3.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trial and practice(to finalize the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anomaly detection method: OneClassSVM\n",
    "# Construct OneClassSVM \n",
    "svm = OneClassSVM(kernel='rbf').fit(X_train, y_train)\n",
    "\n",
    "# Get labels from classifier and cull outliers\n",
    "svm_outliers = svm.predict(X_train)==-1\n",
    "\n",
    "X_svm = X_train[~svm_outliers]\n",
    "y_svm = y_train[~svm_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE', RFE(estimator=LinearSVC(), n_features_to_select=5)),\n",
      "                ('LinearSVC', LinearSVC(C=40))])\n",
      "Score of the best model: 0.9061216551941215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.43      0.59      3395\n",
      "           1       0.63      0.97      0.77      3381\n",
      "\n",
      "    accuracy                           0.70      6776\n",
      "   macro avg       0.79      0.70      0.68      6776\n",
      "weighted avg       0.79      0.70      0.68      6776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1471</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>3287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1471  1924\n",
       "1    94  3287"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model4\n",
    "#Anomaly Detection:OneclassSVM, feature selection: RFE, Classifier: LinearSVC\n",
    "\n",
    "#pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=LinearSVC())),\n",
    "    ('LinearSVC', LinearSVC())                 \n",
    "])\n",
    "\n",
    "# hyperparameter tunning of the classifier and feature selection method\n",
    "param_grid = {'RFE__n_features_to_select': [5, 10, 15],\n",
    "              'LinearSVC__C': [10, 20, 30, 40, 50],\n",
    "              'LinearSVC__penalty': ['l2']\n",
    "              }\n",
    "\n",
    "\n",
    "# building and fitting model on train set\n",
    "model4 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model4.fit(X_svm, y_svm)\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model4.best_estimator_)\n",
    "print(\"Score of the best model:\", model3.best_score_)\n",
    "predicted_y = model4.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=LogisticRegression(), n_features_to_select=10)),\n",
      "                ('LogisticRegression', LogisticRegression(C=5))])\n",
      "Score of the best model: 0.8527514231499052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.46      0.62      3395\n",
      "           1       0.64      0.97      0.77      3381\n",
      "\n",
      "    accuracy                           0.72      6776\n",
      "   macro avg       0.79      0.72      0.70      6776\n",
      "weighted avg       0.79      0.72      0.70      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1572</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>3283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1572  1823\n",
       "1    98  3283"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 5\n",
    "#Anomaly detection: OneclassSVM ,feature selection: RFE, Classifier: Logistic regression\n",
    "#pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=LogisticRegression())),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "\n",
    "#hyperparameter tunning for the classifier and feature selection method\n",
    "param_grid = { 'RFE__n_features_to_select': [10, 15],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "# model building and fitting on training set\n",
    "model5 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model5.fit(X_svm, y_svm)\n",
    "\n",
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model5.best_estimator_)\n",
    "print(\"Score of the best model:\", model5.best_score_)\n",
    "predicted_y = model5.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anamoly Detection Method: SGDOneClassSVM\n",
    "\n",
    "clf = OneClassSVM(nu=0.1, kernel='linear', gamma=0.1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train)\n",
    "\n",
    "# Predict inliers/outliers\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "# Identify and remove outliers\n",
    "mask = y_pred_train == 1\n",
    "X_svml = X_train[mask]\n",
    "y_svml = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()), ('VT', VarianceThreshold()),\n",
      "                ('LogisticRegression', LogisticRegression(C=10))])\n",
      "Score of the best model: 0.6808405964280025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.46      0.58      3395\n",
      "           1       0.61      0.86      0.72      3381\n",
      "\n",
      "    accuracy                           0.66      6776\n",
      "   macro avg       0.69      0.66      0.65      6776\n",
      "weighted avg       0.69      0.66      0.65      6776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1565  1830\n",
       "1   458  2923"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model6\n",
    "#Anomaly detection: SGDOneClassSVM, feature selection methos: Variance Threshold, Classifier: Logistic regression\n",
    "#defining pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('VT', VarianceThreshold()),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "#hyperparameter tunning for feature selection method and classifier\n",
    "param_grid = {'VT__threshold': [0.0],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building and fitting\n",
    "model6 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model6.fit(X_svml, y_svml)\n",
    "\n",
    "\n",
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model6.best_estimator_)\n",
    "print(\"Score of the best model:\", model6.best_score_)\n",
    "predicted_y = model6.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=LogisticRegression(), n_features_to_select=10)),\n",
      "                ('LogisticRegression', LogisticRegression(C=10))])\n",
      "Score of the best model: 0.6799968876862293\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.43      0.55      3395\n",
      "           1       0.60      0.88      0.72      3381\n",
      "\n",
      "    accuracy                           0.65      6776\n",
      "   macro avg       0.69      0.65      0.63      6776\n",
      "weighted avg       0.69      0.65      0.63      6776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1456</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>2963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  1456  1939\n",
       "1   418  2963"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 7\n",
    "#Anomaly detection: SGDOneClassSVM, feature selection method: RFE, Classifier: logistic regression\n",
    "#pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=LogisticRegression())),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "# hyperparameter tunning for classifier and feature selector\n",
    "param_grid = { 'RFE__n_features_to_select': [10, 15],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building and model fitting on train data\n",
    "model7 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model7.fit(X_svml, y_svml)\n",
    "\n",
    "\n",
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model7.best_estimator_)\n",
    "print(\"Score of the best model:\", model7.best_score_)\n",
    "predicted_y = model7.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model8\n",
    "\n",
    "#Anomaly detection: isolation forest, feature selection method: RFE, Classifier: random forest\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=RandomForestClassifier()))\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'RFE__n_features_to_select': [10, 15],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model8 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model8.fit(X_iso, y_iso)\n",
    "\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model8.best_estimator_)\n",
    "print(\"Score of the best model:\", model8.best_score_)\n",
    "predicted_y = model8.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('feature_selection', FactorAnalysis(n_components=20)),\n",
      "                ('rf', RandomForestClassifier(n_estimators=1000))])\n",
      "Score of the best model: 0.8617964575352784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      3395\n",
      "           1       0.82      0.89      0.85      3381\n",
      "\n",
      "    accuracy                           0.85      6776\n",
      "   macro avg       0.85      0.85      0.85      6776\n",
      "weighted avg       0.85      0.85      0.85      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2739</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>369</td>\n",
       "      <td>3012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2739   656\n",
       "1   369  3012"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 9\n",
    "#Anomaly detection: EllipticEnvelope, feature selection: Factor Analysis, classifier: Random Forest\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('feature_selection', FactorAnalysis()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'feature_selection__n_components': [15, 20],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model9 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model9.fit(X_ee, y_ee)\n",
    "\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model9.best_estimator_)\n",
    "print(\"Score of the best model:\", model9.best_score_)\n",
    "predicted_y = model9.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=RandomForestClassifier(),\n",
      "                     n_features_to_select=15)),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(criterion='entropy',\n",
      "                                        n_estimators=1000))])\n",
      "Score of the best model: 0.9098608965604734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      3447\n",
      "           1       0.89      0.93      0.91      3329\n",
      "\n",
      "    accuracy                           0.91      6776\n",
      "   macro avg       0.91      0.91      0.91      6776\n",
      "weighted avg       0.91      0.91      0.91      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3068</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>219</td>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3068   379\n",
       "1   219  3110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model10\n",
    "#Anomaly detection: local outlier factor, feature selection method: factor analysis, Classifier: random forest\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=RandomForestClassifier())),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'RFE__n_features_to_select': [10, 15],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model10 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model10.fit(X_lof, y_lof)\n",
    "\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model10.best_estimator_)\n",
    "print(\"Score of the best model:\", model10.best_score_)\n",
    "predicted_y = model10.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', MinMaxScaler()),\n",
      "                ('FA', FactorAnalysis(n_components=20)),\n",
      "                ('SVC', SVC(C=500, gamma=0.1))])\n",
      "Score of the best model: 0.8453513316672842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      3387\n",
      "           1       0.86      0.73      0.79      3389\n",
      "\n",
      "    accuracy                           0.80      6776\n",
      "   macro avg       0.81      0.80      0.80      6776\n",
      "weighted avg       0.81      0.80      0.80      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2973</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>925</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2973   414\n",
       "1   925  2464"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 11\n",
    "#Anomaly Detection: EllipticEnvelope, feature selection: Factor Analysis, Classifier: kernel SVC \n",
    "pipe = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('FA', FactorAnalysis()), \n",
    "    ('SVC', SVC())  \n",
    "])\n",
    "\n",
    "# hyperparameter tuning of classifiers and feature selection method\n",
    "\n",
    "param_grid = {\n",
    "              'FA__n_components': [15, 20],\n",
    "              'SVC__C': [500, 1000, 5000, 10000], \n",
    "              'SVC__gamma': [0.1, 0.5], \n",
    "              'SVC__kernel': ['rbf']\n",
    "          }\n",
    "\n",
    "\n",
    "model10 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model10.fit(X_ee, y_ee)\n",
    "\n",
    "print(\"Parameters of the best model are:\",model110.best_estimator_)\n",
    "print(\"Score of the best model:\", model10.best_score_)\n",
    "predicted_y = model110.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()), ('PCA', PCA(n_components=20)),\n",
      "                ('LogisticRegression', LogisticRegression(C=10))])\n",
      "Score of the best model: 0.7977224063109549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.79      3387\n",
      "           1       0.76      0.91      0.83      3389\n",
      "\n",
      "    accuracy                           0.81      6776\n",
      "   macro avg       0.83      0.81      0.81      6776\n",
      "weighted avg       0.83      0.81      0.81      6776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2435</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2435   952\n",
       "1   308  3081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 12\n",
    "#Anomaly detection: Isolation Forest, feature selection: PCA, classification: Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('PCA', PCA()),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "# hyperparameter tunning for classifier and feature selector\n",
    "param_grid = { 'PCA__n_components': [15, 20],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building and model fitting on train data\n",
    "model12 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model12.fit(X_iso, y_iso)\n",
    "\n",
    "\n",
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model12.best_estimator_)\n",
    "print(\"Score of the best model:\", model12.best_score_)\n",
    "predicted_y = model12.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('FA', FactorAnalysis(n_components=20)),\n",
      "                ('LogisticRegression', LogisticRegression(C=10))])\n",
      "Score of the best model: 0.8206051853831523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81      3387\n",
      "           1       0.79      0.88      0.83      3389\n",
      "\n",
      "    accuracy                           0.82      6776\n",
      "   macro avg       0.83      0.82      0.82      6776\n",
      "weighted avg       0.83      0.82      0.82      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2587</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394</td>\n",
       "      <td>2995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2587   800\n",
       "1   394  2995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 13\n",
    "#Anomaly detection: Elliptic Envelope, feature selection: Factor Analysis, Classifier: Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('FA', FactorAnalysis()),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "# hyperparameter tunning for classifier and feature selector\n",
    "param_grid = { 'FA__n_components': [15, 20],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building and model fitting on train data\n",
    "model13 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model13.fit(X_ee, y_ee)\n",
    "\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model13.best_estimator_)\n",
    "print(\"Score of the best model:\", model13.best_score_)\n",
    "predicted_y = model13.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('feature_selection', FactorAnalysis(n_components=20)),\n",
      "                ('rf', RandomForestClassifier(n_estimators=1000))])\n",
      "Score of the best model: 0.8652375365424634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      3395\n",
      "           1       0.94      0.96      0.95      3381\n",
      "\n",
      "    accuracy                           0.95      6776\n",
      "   macro avg       0.95      0.95      0.95      6776\n",
      "weighted avg       0.95      0.95      0.95      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3186</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>3257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  3186   209\n",
       "1   124  3257"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model14\n",
    "#Anomaly detection method: Isolation forest, feature selection method: factor analysis, Classifier: random forest\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('feature_selection', FactorAnalysis()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'feature_selection__n_components': [15, 20],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model14 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model14.fit(X_iso, y_iso)\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model14.best_estimator_)\n",
    "print(\"Score of the best model:\", model14.best_score_)\n",
    "predicted_y = model14.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('feature_selection', FactorAnalysis(n_components=20)),\n",
      "                ('rf', RandomForestClassifier(n_estimators=1000))])\n",
      "Score of the best model: 0.8610056311216763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.81      0.84      3395\n",
      "           1       0.82      0.89      0.85      3381\n",
      "\n",
      "    accuracy                           0.85      6776\n",
      "   macro avg       0.85      0.85      0.85      6776\n",
      "weighted avg       0.85      0.85      0.85      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2740</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2740   655\n",
       "1   370  3011"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model15\n",
    "\n",
    "#Anomaly detection method: Elliptic Envelope, feature selection method: factor analysis, Classifier: random forest\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('feature_selection', FactorAnalysis()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "     'feature_selection__n_components': [15, 20],\n",
    "     'rf__n_estimators': [50, 100, 1000],\n",
    "     'rf__min_samples_split': [2, 3, 4],\n",
    "     'rf__criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "#model building and fitting model on train set\n",
    "model15 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model15.fit(X_ee, y_ee)\n",
    "\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "\n",
    "print(\"Parameters of the best model are:\",model15.best_estimator_)\n",
    "print(\"Score of the best model:\", model15.best_score_)\n",
    "predicted_y = model15.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('RFE',\n",
      "                 RFE(estimator=LogisticRegression(), n_features_to_select=10)),\n",
      "                ('LogisticRegression', LogisticRegression(C=9))])\n",
      "Score of the best model: 0.8387108279139843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84      3395\n",
      "           1       0.82      0.90      0.86      3381\n",
      "\n",
      "    accuracy                           0.85      6776\n",
      "   macro avg       0.85      0.85      0.85      6776\n",
      "weighted avg       0.85      0.85      0.85      6776\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2706</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328</td>\n",
       "      <td>3053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2706   689\n",
       "1   328  3053"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model16\n",
    "#Anamoly detection method: Elliptic Envelope, feature selection: RFE, Classifier: Logistic Regression\n",
    "#pipeline defination\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=LogisticRegression())),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "#parameters tunning\n",
    "param_grid = { 'RFE__n_features_to_select': [10, 15],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building\n",
    "model16 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model16.fit(X_ee, y_ee)\n",
    "\n",
    "# Given an unbiased evaluation  \n",
    "# ----------------------------------\n",
    "#confusion matrix, precision, recall, f1-score, accuracy\n",
    "print(\"Parameters of the best model are:\",model16.best_estimator_)\n",
    "print(\"Score of the best model:\", model16.best_score_)\n",
    "predicted_y = model16.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model are: Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('FA', FactorAnalysis(n_components=15)),\n",
      "                ('LogisticRegression', LogisticRegression(C=4))])\n",
      "Score of the best model: 0.7743495296458317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      3395\n",
      "           1       0.74      0.80      0.77      3381\n",
      "\n",
      "    accuracy                           0.76      6776\n",
      "   macro avg       0.76      0.76      0.76      6776\n",
      "weighted avg       0.76      0.76      0.76      6776\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2435</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663</td>\n",
       "      <td>2718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  2435   960\n",
       "1   663  2718"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model17\n",
    "\n",
    "# Anomaly detection method: Elliptic Envelope, Feature selection: Factor Analysis  Classifier: Logistic Regression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('FA', FactorAnalysis()),\n",
    "    ('LogisticRegression', LogisticRegression())                 \n",
    "])\n",
    "# hyperparameter tunning for classifier and feature selector\n",
    "param_grid = { 'FA__n_components': [15, 20],\n",
    "               'LogisticRegression__C': [4, 5, 6, 9, 10]\n",
    "              }\n",
    "\n",
    "#model building and model fitting on train data\n",
    "model17 = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1)\n",
    "model17.fit(X_ee, y_ee)\n",
    "\n",
    "\n",
    "print(\"Parameters of the best model are:\",model17.best_estimator_)\n",
    "print(\"Score of the best model:\", model17.best_score_)\n",
    "predicted_y = model17.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "print(\"Confusion Matrix\")\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelx\n",
    "#classifier: XGB, Feature selection method: RFE\n",
    "#defining pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('RFE', RFE(estimator=XGBClassifier())),\n",
    "    ('XGB', XGBClassifier())\n",
    "])\n",
    "\n",
    "# define a grid of hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "    'RFE__n_features_to_select': [10, 15],\n",
    "    'XGB__max_depth': [3, 7],\n",
    "    'XGB__n_estimators': [50, 200],\n",
    "    'XGB__learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "model4 = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "model4.fit(X_svm, y_svm)\n",
    "\n",
    "\n",
    "model_results4 = pd.DataFrame.from_dict(model4.cv_results_)\n",
    "print(model_results4.sort_values(\"rank_test_score\"))\n",
    "\n",
    "\n",
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "print(\"Parameters of the best model are:\",model4.best_estimator_)\n",
    "print(\"Score of the best model:\", model4.best_score_)\n",
    "predicted_y = model4.predict(X_test)\n",
    "print(classification_report(y_test, predicted_y))\n",
    "\n",
    "\n",
    "\n",
    "# It took more than a hour to execute"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Details of all models and Results below \n",
    "# ---------------------------------------------\n",
    "\n",
    "> I experimented with different Anomaly detection, feature selection and classifier methods, listed below the observations and results as following:\n",
    "\n",
    "Model     Pipeline( Anamoly Detection + Feature selection + Classifier)    Avg. Model Accuracy   Prediction Accuracy(f1-score)\n",
    "\n",
    "model1              EllipticEnvelope + PCA + kernalSVC                              85%                    81%\n",
    "\n",
    "model2      IsolationForest + Factor Analysis+  Linear SVC                          78%                    80%\n",
    "\n",
    "model3        Local Outlier Factor + RFE + Random Forest                            90%                    91%\n",
    "\n",
    "model4           OneClassSVM + RFE + LinearSVC                                      90%                    70%\n",
    "\n",
    "model5           OneClassSVM + RFE + LogisticRegression                             85%                    72%\n",
    "\n",
    "model6       SGDOneClassSVM + VarianceThreshold + LogisticRegression                68%                    66%\n",
    "\n",
    "model7          SGDOneClassSVM + RFE + LogisticRegression                           67%                    65%\n",
    "\n",
    "model8           IsolationForest + RFE + Random Forest                              86%                    85%                            \n",
    "model9          EllipticEnvelope + Factor Analysis + Random Forest                  86%                    85%\n",
    "\n",
    "model10         EllipticEnvelope + RFE + Random Forest                              90%                    91%\n",
    "\n",
    "model11         EllipticEnvelope + Factor Analysis + Kernel SVC                     84%                    80%\n",
    "\n",
    "model12         IsolationForest + PCA + Logistic Regression                         79%                    81%\n",
    "\n",
    "model13       EllipticEnvelope + Factor Analysis + Logistic Regression              82%                    82%\n",
    "\n",
    "model14       IsolationForest + Factor Analysis + Random Forest                     86%                    95%\n",
    "\n",
    "model15       EllipticEnvelope + Factor Analysis + Random Forest                    86%                    85%\n",
    "\n",
    "model16       IsolationForest + RFE + Logistic Regression                           80%                    81%\n",
    "\n",
    "model17      EllipticEnvelope + Factor Analysis + Logistic Regression               77%                    76%\n",
    "\n",
    "\n",
    "> Model3 and model10 gave same results and I saved model3 for future use because it gave the best result with regards to the test dataset as compared to the other models.\n",
    "\n",
    "> Almost all random forest classifier gave better accuracy and predict the test set well irrespective of feature selection and anomaly detection method. Although, with rfe it performed  really well.\n",
    "\n",
    "> I experimented anomaly detection method for example oneclassSVM and SGDOneClassSVM, they did not work well with feature selection methods like rfe, variance threshold and classifiers like logistic regression, linearSVC. Though it perfored better with the train set but did not perform as expected with the test set. It seems to be overfitting.\n",
    "\n",
    ">Other feature selection and classifier methods werked as expected.\n",
    "\n",
    ">From this pool of choices I selected three of the combination for final result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of these three pipelines and findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    ">> In this part of the project, I have experimented with various combinations of anamoly detection, feature selection and classification methods in three different ML pipelines.\n",
    "- I have experimented with various standarization methods as well to know whether these methods have any significant impact on the results. Overall, my final three model details are listed as follows:\n",
    "\n",
    ">>I have considered test data with outliers and without outliers.\n",
    "\n",
    "Overall performance of the model with outliers on the test dataset.\n",
    "\n",
    "\n",
    "Model     Pipeline(Anamoly Detection + Feature selection + Classifier)    Avg. Model Accuracy   Prediction Accuracy(f1-score)\n",
    "\n",
    "model1         EllipticEnvelope + PCA + kernalSVC                                   85%                    82%\n",
    "\n",
    "model2      IsolationForest + Factor Analysis+  Linear SVC                          75%                    74%\n",
    "\n",
    "model3         Local Outlier Factor + RFE + Random Forest                           90%                    91%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Performance of three classifiers result without outliers on test set are following:\n",
    "\n",
    "Model     Pipeline(Anamoly Detection + Feature selection + Classifier)    Avg. Model Accuracy   Prediction Accuracy(f1-score)\n",
    "\n",
    "model1         EllipticEnvelope + PCA + kernalSVC                                   85%                    86%\n",
    "\n",
    "model2      IsolationForest + Factor Analysis+  Linear SVC                          75%                    74%\n",
    "\n",
    "model3         Local Outlier Factor + RFE + Random Forest                           90%                    91%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>>> To compare the overall performance of the model I considered precision, recall, F1 score and confusion matrix. Report scores, confusion matrix, classification reports\n",
    "\n",
    ">>> Model1 pipeline: In model1 first I used used the test data with outliers, from the classification report for class 0, the precision was 0.80, which indicated that 80% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.86, which indicated that 86% of all instances of class 0(non-backorder) were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.83, and this value represents the class 0 f1-score. There were 3402 occurrences of class 0 in the dataset, as shown by the class 0 support of 3402.\n",
    "The precision for class 1(backorder) was 0.84, meaning that 84% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.79, which indicated that 79% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.81, and this value was used to calculate the class 1 f1-score. There were 3374 occurrences of class 1 in the dataset, as shown by the value of 3374 for the support for class 1.\n",
    "The model's accuracy was 0.82, which indicated that it correctly identified the class for 82% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.82. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.82. Overall, this classification report shows that the model performs fairly well with an overall accuracy of 82%.\n",
    "\n",
    "When I applied the model on the test data where outlier was removed, using the classification report for class 0, the precision was 0.87, which indicated that for 87% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.85, which indicated that 85% of all instances of class 0 were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.86, and this value represents the class 0 f1-score. There were 2675 occurrences of class 0 in the dataset, as shown by the class 0 support of 2675.\n",
    "The precision for class 1 was 0.85, meaning that 85% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.88, which indicated that 88% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.87, and this value was used to calculate the class 1 f1-score. There were 2745 occurrences of class 1 in the dataset, as shown by the value of 2745 for the support for class 1.\n",
    "The model's accuracy was 0.86, which indicated that it correctly identified the class for 86% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.86. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.86. Overall, this classification report shows that the model performs fairly well with an overall accuracy of 86%.\n",
    "Here, I tried 5 fold cross validation mean model test score was around .85 and std of test score was .004 approximately. \n",
    "\n",
    "Now, from the confusion matrix of the model (on the test set with outliers) it was clearly understandable that on 6776 datapoints true negative was 2912 (no. of negative data points classified correctly), true positive was 2652 (no. of positive data points classified correctly), false negative was 722 (no. of positive datapoints but predicted negative) and false positive was 490 (no. of negative datapoints but predicted positive). Overall, 82% of the data classified correctly.\n",
    "\n",
    "Next, from the next confusion matrix which generated on the test set(with inliers), out of 5420 data points true negative was 2266 (no. of negative data points classified correctly), true positive was 2407 (no. of positive data points classified correctly), false negative was 338 (no. of positive datapoints but predicted negative) and false positive was 409 (no. of negative datapoints but predicted positive). Overall, 86% of the datapoints are predicted correctly. \n",
    "\n",
    "In both the cases the model has a relatively high number of false negative and false positive cases. So, to improve the precision and recall, the model can be trained with more positive and negative samples, or the model architecture can be improved to better capture the positive and negative classes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>> Model2 pipeline: Firstly, I applied model2 on test dataset with outliers, from the classification report for class 0(non-backorder), the precision was 0.83, which indicated that 83% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.60, which indicated that 60% of all instances of class 0 were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.70, and this value represents the class 0 f1-score. There were 3402 occurrences of class 0 in the dataset, as shown by the class 0 support of 3402.\n",
    "The precision for class 1(backorder) was 0.68, meaning that 68% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.88, which indicated that 88% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.77, and this value was used to calculate the class 1 f1-score. There were 3374 occurrences of class 1 in the dataset, as shown by the value of 3374 for the support for class 1.\n",
    "The model's accuracy was 0.74, which indicated that it correctly identified the class for 74% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.73. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.73.\n",
    "\n",
    "Further, I applied this model to the test data with inliers and there was no change on the overall result. The classification report for class 0, the precision was 0.83, which indicated that 83% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.60, which indicated that 60% of all instances of class 0 were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.70, and this value represents the class 0 f1-score. There were 3224 occurrences of class 0 in the dataset, as shown by the class 0 support of 3224.\n",
    "The precision for class 1 was 0.69, meaning that 69% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.88, which indicated that 88% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.77, and this value was used to calculate the class 1 f1-score. There were 3213 occurrences of class 1 in the dataset, as shown by the value of 3213 for the support for class 1. \n",
    "The model's accuracy was 0.74, which indicated that it correctly identified the class for 74% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.73. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.73. In this model there was no significant chage on the test data with or without outlier. \n",
    "Overall, in both the model the precision and recall values show that the model had a higher precision for class 0 than for class 1, which means that the model was better at correctly identifying class 0 instances than class 1 instances. On the other hand, the recall for class 1 was higher than for class 0, which means that the model was better at correctly identifying class 1 instances than class 0 instances. The f1-score, which was the harmonic mean of precision and recall, gives a more balanced evaluation of the model's performance for both classes.\n",
    "\n",
    "\n",
    "Here, I used 5 fold cross validation and mean model test score was around .76 and stdev of test score was .01 approximately. \n",
    "Now, from the confusion matrix of the model(on the test set with outliers) it was clearly understandable that on 6776 datapoints true negative was 2034(no. of negative data points classified correctly), true positive was 2962(no. of positive data points classified correctly), false nagative was 412(no. of positive datapoints but predicted negative) and false positive was 1368(no. of negative datapoints but predicted positive). Overall, 74% of the data classified correctly.\n",
    "\n",
    "Next, from the next confusion matrix which generated on the test set(with inliers), out of 6437 data points true negative was 1929(no. of negative data points classified correctly), true positive was 2819(no. of positive data points classified correctly), false nagative was 394(no. of positive datapoints but predicted negative) and false positive was 1295(no. of negative datapoints but predicted positive). Overall, 74% of the datapoints are predicted correctly. \n",
    "\n",
    "In both the cases the model has a relatively high number of false negative than false positive cases. So, to improve the recall, the model can be trained with more positive, or the model architecture can be improved to better capture the positive class.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>> Model3 pipeline: Similarly, I applied the same procedure for model3. On the first scenario, outlier on test data set, the classification report for class 0(non-backorder), the precision was 0.93, which indicated that 93% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.89, which indicated that 89% of all instances of class 0 were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.91, and this value represents the class 0 f1-score. There were 3402 occurrences of class 0 in the dataset, as shown by the class 0 support of 3402.\n",
    "The precision for class 1(backorder) was 0.89, meaning that 89% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.93, which indicated that 93% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.91, and this value was used to calculate the class 1 f1-score. There were 3374 occurrences of class 1 in the dataset, as shown by the value of 3374 for the support for class 1.\n",
    "The model's accuracy was 0.91, which indicated that it correctly identified the class for 91% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.91. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.91.\n",
    "\n",
    "Furtuer, I applied model to the test data set with inliers and there was no change on the overall result. The classification report for class 0, the precision was 0.93, which indicated that 93% of the cases the model correctly identified as belonging to class 0 were observed. Recall for class 0 was 0.89, which indicated that 89% of all instances of class 0 were correctly predicted by the model. The harmonic mean of precision and recall for class 0 was 0.91, and this value represents the class 0 f1-score. There were 2968 occurrences of class 0 in the dataset, as shown by the class 0 support of 2968.\n",
    "The precision for class 1 was 0.90, meaning that 90% of the occurrences the model predicted to be in class 1 were in fact in class 1. Recall for class 1 was 0.94, which indicated that 94% of all occurrences that belong to class 1 were correctly predicted by the model. The harmonic mean of precision and recall for class 1 was 0.92, and this value was used to calculate the class 1 f1-score. There were 3091 occurrences of class 1 in the dataset, as shown by the value of 3091 for the support for class 1. \n",
    "The model's accuracy was 0.91, which indicated that it correctly identified the class for 91% of the dataset's cases. The unweighted average of the f1 scores for both classes, known as the macro-averaged f1-score, was 0.91. The average of the f1-scores for the two classes, weighted by the quantity of occurrences in each class, was 0.91. In this model there is no significant chage on the test data with or without outlier. \n",
    "Overall, in both the model the precision and recall values show that the model has a higher precision for class 0 than for class 1, which means that the model is better at correctly identifying class 0 instances than class 1 instances. On the other hand, the recall for class 1 is higher than for class 0, which means that the model is better at correctly identifying class 1 instances than class 0 instances. The f1-score, which is the harmonic mean of precision and recall, gives a more balanced evaluation of the model's performance for both classes.\n",
    "\n",
    "In both the cases, the precision and recall values for both classes are high, indicating that the model was good at predicting both classes. The f1-score was also high for both classes, which indicated that the model was well-balanced in terms of precision and recall. Overall, those classification reports indicate that the models perform well, with high accuracy and f1-score. The model appears to be equally good at predicting both classes, with only slight differences in precision and recall between the two classes.\n",
    "\n",
    "Here, I used 5 fold cross validation mean model test score was around .90 and std of test score was .003 approximately. \n",
    "Now, from the confusion matrix of the model(on the test set with outliers) it was clearly understandable that on 6776 datapoints true negative was 3029(no. of negative data points classified correctly), true positive was 3141(no. of positive data points classified correctly), false nagative was 233(no. of positive datapoints but predicted negative) and false positive was 373(no. of negative datapoints but predicted positive). Overall, 91% of the data classified correctly.\n",
    "Although this model captured more number of positive and negative cases accurately, from the next confusion matrix which generated on the test set(with inliers), out of 6059 data points true negative was 2643(no. of negative data points classified correctly), true positive was 2900(no. of positive data points classified correctly), false nagative was 191(no. of positive datapoints but predicted negative) and false positive was 325(no. of negative datapoints but predicted positive). Overall, 91% of the datapoints are predicted correctly. \n",
    "\n",
    "In both the cases the models has a bit more high number of false negative than false positive cases. To improve the recall, the model can be trained with more positive, or the model architecture can be improved to better capture the positive class.\n",
    "\n",
    "\n",
    ">>> SUMMARY: After comparing the three pipelines and their performance it was clear that model3 performed better as compared to the other two models (model1, model2). Possibly, in the next module, we will be able to conclude such inferences in a better way. Therefore,  I have saved all three model for the use of next module but I will go with model3 at first.  \n",
    "\n",
    "\n",
    ">>> SPECIAL NOTE: I tried XG boost classifier with RFE feature selection method and it took more than a hour but did not show any result. I tried with a few parameters as well but found no positive findings.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model1_pca_ksvc.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bestmodel1, 'model1_pca_ksvc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model2_fa_lsvc.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bestmodel2, 'model2_fa_lsvc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model3_rfe_rf.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bestmodel3, 'model3_rfe_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_sample_data_v1.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for dumping \n",
    "joblib.dump([iso_forest, bestmodel3], 'data_sample_data_v1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
